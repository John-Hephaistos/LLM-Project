{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements: pycaret, openai, tiktoken.\n",
        "Get all neccessary imports"
      ],
      "metadata": {
        "id": "UxCnAbCu1RPa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR_G1SOVWLG2",
        "outputId": "54cb3ec7-8ba3-460a-8ffc-256fc3812159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up client and API key.\n",
        "The API key can be founds in the submission comments. If there are any errors email me: v.vasile.1@student.rug.nl\n",
        "The API key leads to my account - toped it off with 10-20 euros if the Grader whats to test the models. FIne tuning will take a while, depending on which model you wish to run. For the GPT 4.o mini duration is around 20 minutes"
      ],
      "metadata": {
        "id": "oQeYFeED1Wqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "m-_YiocYWoAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train and validation json datasets must be first sent to the openAI client to be processed and approved for fine tuning"
      ],
      "metadata": {
        "id": "MkWdyO0X17lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = client.files.create(\n",
        "  file=open(\"train_data_prepared_gpt4.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "KWTKpxMtWpQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation = client.files.create(\n",
        "  file=open(\"val_data_prepared_gpt4.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "gBe44O53XhZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will beging the fine tuning process for the babbage model - run the cell bellow -  client.fine_tuning.jobs.list(limit=10) - to keep track of the training process\n",
        "! Cannot be used anymore, since openAI has removed it from their line-up. Can only use the saved model"
      ],
      "metadata": {
        "id": "xmQqDEQx2L8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_name = 'LLM-test-babbage-2'\n",
        "babbage = client.fine_tuning.jobs.create(\n",
        "  training_file=train.id,\n",
        "  validation_file = validation.id,\n",
        "  model=\"babbage-002\",\n",
        "  suffix = suffix_name\n",
        ")"
      ],
      "metadata": {
        "id": "yh5y_sRaXEbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will beging the fine tuning process for the GPT 4.o mini model - run the cell bellow -  client.fine_tuning.jobs.list(limit=10) - to keep track of the training process. Number of epochs is set to 1 in order to allow the fine tuning to finish quicker (and save on fonds). In their guide, openAI state that 1-2 epochs with our size of data is more than sufficient"
      ],
      "metadata": {
        "id": "wpnF93Se2dwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_name = 'LLM-test-gpt4_mini'\n",
        "babbage = client.fine_tuning.jobs.create(\n",
        "  training_file=train.id,\n",
        "  validation_file = validation.id,\n",
        "  model=\"gpt-4o-mini-2024-07-18\",\n",
        "  suffix = suffix_name,\n",
        "  hyperparameters={\n",
        "    \"n_epochs\":1\n",
        "  }\n",
        ")"
      ],
      "metadata": {
        "id": "5CzmD9QsOWkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this to observe when the fine tuning jobs complete. Look out for specific model ID. Hyperparameters are also showcased here"
      ],
      "metadata": {
        "id": "VrrlXag5289I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.list(limit=10)"
      ],
      "metadata": {
        "id": "yTBUCkDMXGXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51e0a9c-de9a-4559-9f69-6a7756b8cc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-GibTH5O00r9JRCj9XQ1FJ0PF', created_at=1729434688, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal:llm-test-gpt4-mini:AKRt8nrO', finished_at=1729437124, hyperparameters=Hyperparameters(n_epochs=1, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-dFi2vKaEL8Ji0RrvZiU3sERC', result_files=['file-zHV0bVZxKE0Mas7TteAqrB5X'], seed=618936894, status='succeeded', trained_tokens=1412182, training_file='file-NcSlzaNsjISbDQke8ivtOPQx', validation_file='file-sIwKOCkgwEyNO5D9vJJfperl', estimated_finish=None, integrations=[], user_provided_suffix='LLM-test-gpt4_mini'), FineTuningJob(id='ftjob-YW7Pz3fk1wUjh1l4EqzlwcxP', created_at=1729432988, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Input file file-RToSCnWtsZCfh2NzJ0do4OxP is in the prompt-completion format, but the specified model gpt-4o-mini-2024-07-18 is a chat model and requires chat-formatted data. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for details.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-dFi2vKaEL8Ji0RrvZiU3sERC', result_files=[], seed=460690262, status='failed', trained_tokens=None, training_file='file-RToSCnWtsZCfh2NzJ0do4OxP', validation_file='file-aHXE1IrK7PAxXpG2MfVjxnWH', estimated_finish=None, integrations=[], user_provided_suffix='LLM-test-gpt4_mini'), FineTuningJob(id='ftjob-LmGotlBpqjCUnBryo6QSTelM', created_at=1729413344, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:babbage-002:personal:llm-test-babbage-2:AKLrjmt4', finished_at=1729413973, hyperparameters=Hyperparameters(n_epochs=3, batch_size=7, learning_rate_multiplier=16), model='babbage-002', object='fine_tuning.job', organization_id='org-dFi2vKaEL8Ji0RrvZiU3sERC', result_files=['file-mklNZ2QeamnxgVH45OmWqECm'], seed=188279586, status='succeeded', trained_tokens=3473697, training_file='file-I7jOzVQZShLmncuqaZZr3zDU', validation_file='file-0tRH7B0sJTlF21uMrLMTdcOB', estimated_finish=None, integrations=[], user_provided_suffix='LLM-test-babbage-2'), FineTuningJob(id='ftjob-ZIef2VpDCZxghCdM09ZVxOVI', created_at=1728897235, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:babbage-002:personal:llm-test-babbage:AIBcFEDq', finished_at=1728897918, hyperparameters=Hyperparameters(n_epochs=3, batch_size=7, learning_rate_multiplier=16), model='babbage-002', object='fine_tuning.job', organization_id='org-dFi2vKaEL8Ji0RrvZiU3sERC', result_files=['file-cdxurahE8c15Zbk72tKfJjPG'], seed=1493390531, status='succeeded', trained_tokens=3497685, training_file='file-ZNpJ1m9FHwFdKm8w8M6vczEZ', validation_file='file-HaDAqXgFW8MKCmwedZQzYpPK', estimated_finish=None, integrations=[], user_provided_suffix='LLM-test-babbage'), FineTuningJob(id='ftjob-kKxRiK4wWUvXV3doCrzrhC5l', created_at=1728864082, error=Error(code='invalid_training_file', message='The job failed due to an invalid training file. Invalid file format. Example 1 completion contains an invalid token: <|endoftext|>.', param='training_file'), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-dFi2vKaEL8Ji0RrvZiU3sERC', result_files=[], seed=293638805, status='failed', trained_tokens=None, training_file='file-VrlyTEGi72w1qjE5YQV19IyM', validation_file='file-CDQGC5Bw8leRUs1o8Q6DeyEe', estimated_finish=None, integrations=[], user_provided_suffix='LLM-test-babbage')], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be cautious when runing the fine-tuning jobs - you are using real money!\n",
        "The models are already saved and can be acces instantly!\n",
        "babbage_id = ftjob-ZIef2VpDCZxghCdM09ZVxOVI\n",
        "4.o mini_id = ft:gpt-4o-mini-2024-07-18:personal:llm-test-gpt4-mini:AKRt8nrO\n"
      ],
      "metadata": {
        "id": "MxJonLmKWlQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the model ids"
      ],
      "metadata": {
        "id": "6hbcs2-73f5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "babbage_id = 'ft:babbage-002:personal:llm-test-babbage-2:AKLrjmt4'\n",
        "gpt4_mini_id = 'ft:gpt-4o-mini-2024-07-18:personal:llm-test-gpt4-mini:AKRt8nrO'"
      ],
      "metadata": {
        "id": "VDNvCHXHWklh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the models"
      ],
      "metadata": {
        "id": "oStEhvuFfqcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import sklearn metrics - for all models we are using ccuracy_score, precision_score, recall_score, f1_score."
      ],
      "metadata": {
        "id": "3lvKuiOu3jVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "rJvJk_yRfqMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the path to the test data"
      ],
      "metadata": {
        "id": "IUKqfVy03q3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jsonl_file_path = 'test_data_prepared_gpt4.jsonl'"
      ],
      "metadata": {
        "id": "pnQ2mv8vY3pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function load_test_messages_from_jsonl will extract the prompts from the json file - makes its easier to process and give them to the models"
      ],
      "metadata": {
        "id": "Iv8jIcmG3u-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def load_test_messages_from_jsonl(jsonl_file_path):\n",
        "    test_prompts = []\n",
        "    with open(jsonl_file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            data = json.loads(line.strip())\n",
        "            test_prompts.append(data['messages'])\n",
        "    return test_prompts"
      ],
      "metadata": {
        "id": "USXcNXpOYtqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load test prompts"
      ],
      "metadata": {
        "id": "V9QHM9g537Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts = load_test_messages_from_jsonl(jsonl_file_path)"
      ],
      "metadata": {
        "id": "4yqR5Rq4ZPNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify if format is in order - needs to follow the style:\n",
        "[{'role': 'system',\n",
        "  'content': -prompt-},\n",
        "  {'role': 'system',\n",
        "  'content': -movie review-}]\n",
        "The prompt is the same as the Prompt engineered version."
      ],
      "metadata": {
        "id": "zEMjxKQ539jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hrsc5iyaoJu",
        "outputId": "2d6ce7ca-46a6-4035-be1f-7e56ef9e391b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'As a social scientist, your task is to analyze the sentiment of user movie reviews extracted from IMDB. Please assign a sentiment score of 1 or 2 for each movie review, where 1 signifies positive sentiment, and 2 corresponds to negative sentiment.'},\n",
              " {'role': 'user',\n",
              "  'content': 'The first time I saw this film  I wanted to like it for so many reasons  but I simply did not  It just seemed a little dull  But there was a tiny question I had about something I saw near the beginning of the film so I watched it again  and then finally it clicked for me  I first watched the movie knowing the  surprise ending   and while I definitely wouldn t recommend having the ending spoiled for you  I have still thoroughly enjoyed the bulk of the film and discovering the many seemingly insignificant events that all unravel to point to a very sinister scheme  br    br   I don t think that everyone will love this movie  or even like it  If you like any of the actors  you ll like this movie because the acting is fairly strong and they all get a lot of screen time  If you like mysteries  namely Hitchcock  you ll like this movie  If you like independent or psychological films  you ll like this movie  It really worked for me on all of those levels  If you don t like the actors  mysterious plots or psychological elements  you might not like this movie  But that s your loss  Personally  the only thing that irked me a little was the accents  Good try  Alan Rickman  on the American dialect  but it wasn t much improvement from the scene in Die Hard   The wonderful voice makes up for the weird accent though   The medley of accents in the movie was a little odd  but it was not so distracting that it became difficult or particularly irritating  Also  the camera change from scene to scene was evident and might bother some people  but I actually think it added to the scenes  or scene  I can really only recall one scene where the change was severely different  but it worked   br    br   When you see this movie  see it at least twice  The second time you see it  I hope you realize how intricate the plot really is  Every time I watch this movie  it s under an hour and a half so multiple viewings are not difficult  I seem to notice something else about it and find myself wondering   Why did that just happen   or  Was that intentional   I like movies that make me think  This one does  So just see it  Twice '}]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the test prompts and create the predictions"
      ],
      "metadata": {
        "id": "Qyv_IVEw5pD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts = pd.read_csv('test_data.csv')"
      ],
      "metadata": {
        "id": "SuoL5LgD66r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pCNfMAVTOkTy",
        "outputId": "8c324813-f1fe-4268-a12b-49850d2f1e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt  completion\n",
              "0  A movie theater with a bad history of past gru...           2\n",
              "1  The first time I saw this film  I wanted to li...           1\n",
              "2  I have watched some pretty poor films in the p...           2\n",
              "3  The fact that a film is on DVD doesn t guarant...           2\n",
              "4  I m not a huge Star Trek fan  but I was lookin...           2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f990c303-77e1-4639-90be-471df178a0b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A movie theater with a bad history of past gru...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The first time I saw this film  I wanted to li...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have watched some pretty poor films in the p...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The fact that a film is on DVD doesn t guarant...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I m not a huge Star Trek fan  but I was lookin...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f990c303-77e1-4639-90be-471df178a0b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f990c303-77e1-4639-90be-471df178a0b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f990c303-77e1-4639-90be-471df178a0b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7aa8e670-9ca5-47c4-a041-535ce0f66724\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aa8e670-9ca5-47c4-a041-535ce0f66724')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7aa8e670-9ca5-47c4-a041-535ce0f66724 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Not a  woman film  but film for the gang  One of the worst films ever made by a male director about woman  Director Andy McKay simply doesn t know woman  Peaks of bad taste  American Pie s humor style  crude story  no sense  groundless story  refuted characters  Vulgar fantasies came to life on screen  Insulting and definitely not funny  I wonder how three good actresses accepted to take part in it \",\n          \"I enjoyed watching Cliffhanger  at the beginning when that woman  Sarah  was full of terror when she was slipping  i thought that was a terrifying scene as i would think that when you see that see  your nerves in your body get to you because it makes you get full of fright and your heart beats faster  I did like watching Cliffhanger  i think Silvestar Stallone is a great actor and i think he ll be known as playing Rambo and Rocky \",\n          \"George Cukor s The Women remains one of the glittering gems of 1939  Hollywood s most golden of golden years  The film crackled and sparked and it s absence of males was a subtle touch  hardly noticed because of all the fine entertainment  br    br   Flash forward  We see Fifth Avenue in New York City  in front of Saks  Large crowds bustle along the Avenue   but something s off  The shot reveals only well dressed  attractive and young  women  Creepier than I Am Legend  the visual concept continues  inside the store and later at a large fashion show  What NYC fashion show doesn t have at least 5 gay men  The  no men  rule is rammed down our throats creating an alien world  off balance and distracting  br    br   Enter Meg Ryan  first seen digging in her garden wearing a ridiculous get up complete with her retro curls and flailing arms  I immediately sympathized with her husband and could understand why he looked elsewhere  Later in the film she morphs into an older Jennifer Aniston look and keeps her arms at her sides  This seems intentional as if to say  Look  I can still be relevant   Ryan s character is loaded down with a coven of miss matched friends  insert Sex and the City comparison here  who  if it were real life  would despise each other  Annette Bening plays the power bitch  who during the course of the film realizes her life s dream doesn t really make her happy  Jada Pinkett Smith is the power lesbian  all atitudinous with no use for any of the men who aren t there  Debra Messing is some sort of baby factory that eats a lot  Eva Mendes is an odd choice for the bad girl to say the least  She looks fake  acts fake and any humor she tries to demonstrate falls flat  Someone s comment on here that she looked trans gender was spot on  Other various stars show up  to rearrange the furniture on this Titanic  br    br   The only thing that would have saved this would have been the brilliant casting of Jennifer Aniston and Angelina Jolie  They could have named their price  tucked their tongues firmly into their cheeks and pulled off something very clever and profitable  But no  Hollywood thinks of itself way too highly for that kind of exploitation  Instead we re given this thing that lumbers along awkwardly with no sparkle  Entire sections of dialog from the original are lifted and plopped down into a scene with awful results  At one point Ryan exclaims something along the lines of   This isn t a 1930 s movie   No Meg  it s not \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The client.chat.completions.create function will created the responsed based on the inputs coming from the testing data. Temerature, top_p, frequency_penalty and presence_penalty are set as they are to allow for deterministic outputs\n",
        "\n",
        "The for loop performs the client.chat.completions.create for each of the test reviews, and stores their results in a pandas dataframe\n"
      ],
      "metadata": {
        "id": "gMOywPxD5ZU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_rows = []\n",
        "for msg in test_prompts:\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"ft:gpt-4o-mini-2024-07-18:personal:llm-test-gpt4-mini:AKRt8nrO\",\n",
        "    messages=msg,\n",
        "    temperature=0,\n",
        "    max_tokens=1,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  print(completion.choices[0].message.content)\n",
        "  processed_rows.append(completion.choices[0].message.content)\n",
        "processed_df = pd.DataFrame(processed_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPel99GE6Cy7",
        "outputId": "f065d7c9-9537-4177-dcdd-59cad349bb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "2\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = sentiment(test_data, 'prompt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FLVPZSnXbj75",
        "outputId": "f07ebaa5-e636-4c87-9776-120317bbd443",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt        A movie theater with a bad history of past gru...\n",
            "completion                                                    2\n",
            "Name: 0, dtype: object\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"You provided an invalid 'prompt'. Your prompt was provided in list with str and int.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-6945dd2328b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prompt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-631774bd7821>\u001b[0m in \u001b[0;36msentiment\u001b[0;34m(df, text_column)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Get the model response for the current row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion_from_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbabbage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprocessed_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprocessed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-631774bd7821>\u001b[0m in \u001b[0;36mget_completion_from_messages\u001b[0;34m(messages, model, temperature, token_limit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_completion_from_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpt4_mini_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresence_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     ) -> Completion | Stream[Completion]:\n\u001b[0;32m--> 539\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0;34m\"/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m         )\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    955\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"You provided an invalid 'prompt'. Your prompt was provided in list with str and int.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OMHOb5hYOuZC",
        "outputId": "b1f3eafd-6fd4-4ef9-b173-7c6d05525b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                prompt  completion response\n",
              "0    A movie theater with a bad history of past gru...           2        2\n",
              "1    The first time I saw this film  I wanted to li...           1        1\n",
              "2    I have watched some pretty poor films in the p...           2        2\n",
              "3    The fact that a film is on DVD doesn t guarant...           2        2\n",
              "4    I m not a huge Star Trek fan  but I was lookin...           2        2\n",
              "..                                                 ...         ...      ...\n",
              "495  An interesting slasher film with multiple susp...           2        2\n",
              "496  i watched this series when it first came out i...           1        1\n",
              "497  Once again Jet Li brings his charismatic prese...           1        1\n",
              "498  I rented this movie  after hearing Chris Gore ...           2        2\n",
              "499  This was a big disappointment for me  I think ...           2        2\n",
              "\n",
              "[500 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8502ecaf-8ab0-4ee8-b9a7-5352dd742049\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A movie theater with a bad history of past gru...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The first time I saw this film  I wanted to li...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have watched some pretty poor films in the p...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The fact that a film is on DVD doesn t guarant...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I m not a huge Star Trek fan  but I was lookin...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>An interesting slasher film with multiple susp...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>i watched this series when it first came out i...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Once again Jet Li brings his charismatic prese...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>I rented this movie  after hearing Chris Gore ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>This was a big disappointment for me  I think ...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8502ecaf-8ab0-4ee8-b9a7-5352dd742049')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8502ecaf-8ab0-4ee8-b9a7-5352dd742049 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8502ecaf-8ab0-4ee8-b9a7-5352dd742049');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f2e4c99-d792-4f30-9b94-aa082b791e21\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f2e4c99-d792-4f30-9b94-aa082b791e21')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f2e4c99-d792-4f30-9b94-aa082b791e21 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ed4c556c-615d-490a-ab27-788ff9e1fdab\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('predictions')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ed4c556c-615d-490a-ab27-788ff9e1fdab button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('predictions');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictions",
              "summary": "{\n  \"name\": \"predictions\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Not a  woman film  but film for the gang  One of the worst films ever made by a male director about woman  Director Andy McKay simply doesn t know woman  Peaks of bad taste  American Pie s humor style  crude story  no sense  groundless story  refuted characters  Vulgar fantasies came to life on screen  Insulting and definitely not funny  I wonder how three good actresses accepted to take part in it \",\n          \"I enjoyed watching Cliffhanger  at the beginning when that woman  Sarah  was full of terror when she was slipping  i thought that was a terrifying scene as i would think that when you see that see  your nerves in your body get to you because it makes you get full of fright and your heart beats faster  I did like watching Cliffhanger  i think Silvestar Stallone is a great actor and i think he ll be known as playing Rambo and Rocky \",\n          \"George Cukor s The Women remains one of the glittering gems of 1939  Hollywood s most golden of golden years  The film crackled and sparked and it s absence of males was a subtle touch  hardly noticed because of all the fine entertainment  br    br   Flash forward  We see Fifth Avenue in New York City  in front of Saks  Large crowds bustle along the Avenue   but something s off  The shot reveals only well dressed  attractive and young  women  Creepier than I Am Legend  the visual concept continues  inside the store and later at a large fashion show  What NYC fashion show doesn t have at least 5 gay men  The  no men  rule is rammed down our throats creating an alien world  off balance and distracting  br    br   Enter Meg Ryan  first seen digging in her garden wearing a ridiculous get up complete with her retro curls and flailing arms  I immediately sympathized with her husband and could understand why he looked elsewhere  Later in the film she morphs into an older Jennifer Aniston look and keeps her arms at her sides  This seems intentional as if to say  Look  I can still be relevant   Ryan s character is loaded down with a coven of miss matched friends  insert Sex and the City comparison here  who  if it were real life  would despise each other  Annette Bening plays the power bitch  who during the course of the film realizes her life s dream doesn t really make her happy  Jada Pinkett Smith is the power lesbian  all atitudinous with no use for any of the men who aren t there  Debra Messing is some sort of baby factory that eats a lot  Eva Mendes is an odd choice for the bad girl to say the least  She looks fake  acts fake and any humor she tries to demonstrate falls flat  Someone s comment on here that she looked trans gender was spot on  Other various stars show up  to rearrange the furniture on this Titanic  br    br   The only thing that would have saved this would have been the brilliant casting of Jennifer Aniston and Angelina Jolie  They could have named their price  tucked their tongues firmly into their cheeks and pulled off something very clever and profitable  But no  Hollywood thinks of itself way too highly for that kind of exploitation  Instead we re given this thing that lumbers along awkwardly with no sparkle  Entire sections of dialog from the original are lifted and plopped down into a scene with awful results  At one point Ryan exclaims something along the lines of   This isn t a 1930 s movie   No Meg  it s not \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save predictions in a csv file"
      ],
      "metadata": {
        "id": "JXhxn_L37w23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.to_csv('results_gpt4_fine_tuning.csv')"
      ],
      "metadata": {
        "id": "rzkplryHOvq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "3uWxmzUMOkh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert predictions to numpy array\n",
        "Check if predictions match the shape of ground truth"
      ],
      "metadata": {
        "id": "tiCyL2NR71pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions['response']\n",
        "ground_truth = test_data['completion']\n",
        "predictions = predictions.apply(lambda x: 1 if x == '1' else 2)\n",
        "predictions = np.array(predictions)\n",
        "ground_truth = np.array(ground_truth)\n",
        "print(predictions)\n",
        "print(ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQlJM7v5OyqX",
        "outputId": "279db105-d442-4ea7-bb14-39c53a08bc18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 2 2 2 2 1 2 2 2 2 1 2 1 2 2 1 2 2 2 1 1 2 1 1 2 2 1 1 1 1 1 2 2 1 2 2\n",
            " 2 2 1 2 1 2 2 2 1 1 2 1 2 1 2 2 1 1 1 1 1 1 2 2 1 2 2 2 1 1 1 1 1 1 2 2 1\n",
            " 1 2 2 1 1 1 1 1 1 2 1 1 2 1 2 2 2 2 1 2 2 1 2 1 2 1 1 1 1 2 1 1 2 1 2 1 1\n",
            " 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 2 1 2 1 2 2 1 2 1 1 2 1 2 1 1 2 1 1 1 1 2\n",
            " 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 1 1 2 1 2 1 1 2 2 1 1 2 1 1 1 2 2 1 2 1 2\n",
            " 2 2 1 1 2 1 1 2 1 1 1 1 2 2 2 1 1 2 2 1 2 1 2 2 2 1 2 2 2 1 2 1 2 1 2 1 2\n",
            " 1 2 2 2 2 2 2 1 1 2 1 2 2 2 2 1 2 2 1 2 1 2 1 2 2 2 2 1 1 2 1 2 1 2 1 1 1\n",
            " 2 2 2 2 2 2 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 1 2 1 2 1 2 2 2 1 1 2 2 1 2 2 1\n",
            " 2 1 1 2 2 1 2 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 2 1 2 1 1 1 1 1 2 1 2 2 2\n",
            " 2 1 1 1 1 1 2 1 2 2 1 2 2 1 1 2 2 2 2 2 2 1 1 2 2 1 1 2 2 2 2 1 1 2 1 1 1\n",
            " 1 2 1 1 2 2 1 1 1 2 2 2 2 1 2 1 1 1 1 2 1 2 2 1 2 2 2 2 2 1 2 2 1 2 1 2 1\n",
            " 2 1 2 1 2 2 2 2 1 1 2 2 1 1 1 2 2 1 2 1 2 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 1\n",
            " 1 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 1 2 1 2 2 2 1 1 2 2 1 1 2 1 2 2 2 1 1\n",
            " 1 2 2 2 2 2 2 2 1 2 2 1 2 1 2 1 1 2 2]\n",
            "[2 1 2 2 2 2 1 2 2 2 2 1 2 1 2 2 1 2 2 2 1 1 2 1 1 2 2 1 1 1 1 1 2 2 1 2 2\n",
            " 2 2 1 2 1 2 2 2 1 1 2 1 1 1 2 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 1 2 2 1\n",
            " 1 2 2 1 1 1 1 1 1 2 1 1 2 1 2 2 2 1 1 2 2 1 2 1 2 1 1 1 1 2 1 1 2 1 2 1 1\n",
            " 2 1 2 1 1 2 1 1 1 1 2 1 2 2 2 1 2 1 2 1 2 2 1 2 1 1 2 1 2 1 1 2 1 1 1 1 2\n",
            " 1 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2\n",
            " 2 2 1 1 2 1 1 2 1 1 1 1 2 2 2 1 1 2 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 1 2 1 2\n",
            " 1 2 2 2 2 2 2 2 1 2 1 2 2 2 2 1 2 2 1 2 1 2 1 2 2 2 2 1 1 2 1 2 1 2 1 1 1\n",
            " 2 2 2 2 2 2 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 1 2 1 2 1 2 2 2 1 1 2 2 1 2 2 1\n",
            " 1 1 1 2 2 1 2 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 2 1 2 1 1 1 1 1 2 1 2 2 2\n",
            " 2 1 1 1 1 1 2 1 2 2 1 2 2 1 1 2 2 2 2 2 2 1 1 2 2 1 1 2 2 2 2 1 1 2 1 1 1\n",
            " 1 2 1 1 2 2 1 1 1 2 2 2 2 1 2 1 1 1 1 2 1 2 2 1 2 2 2 2 2 1 2 2 1 2 1 2 1\n",
            " 2 1 2 1 2 2 2 2 1 1 2 2 1 1 1 2 2 1 2 1 2 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 1\n",
            " 1 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 1 2 1 2 2 2 1 1 2 2 1 1 2 1 2 2 2 1 1\n",
            " 1 2 2 2 2 2 2 2 1 2 2 1 2 1 2 1 1 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare predictions to ground truth - Accuracy, Precision, Recall, F1 Score"
      ],
      "metadata": {
        "id": "RY03-NHF76vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "accuracy = accuracy_score(ground_truth, predictions)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(ground_truth, predictions, pos_label=1)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(ground_truth, predictions, pos_label=1)\n",
        "\n",
        "# F1 Score\n",
        "f1 = f1_score(ground_truth, predictions, pos_label=1)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "_PwEQSTNPbpG",
        "outputId": "ed9e5ca7-816a-4b37-98f9-cc6af55cfbdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.984\n",
            "Precision: 0.9874476987447699\n",
            "Recall: 0.979253112033195\n",
            "F1 Score: 0.9833333333333333\n"
          ]
        }
      ]
    }
  ]
}